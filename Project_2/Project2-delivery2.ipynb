{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "import scipy.cluster.hierarchy as shc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "features = pd.read_csv('./medical/historical_X.dat', header=None, sep=\" \").values\n",
    "actions = pd.read_csv('./medical/historical_A.dat', header=None, sep=\" \").values\n",
    "outcome = pd.read_csv('./medical/historical_Y.dat', header=None, sep=\" \").values\n",
    "observations = features[:, :128]\n",
    "labels = features[:,128] + features[:,129]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by implementing a model\n",
    "\n",
    "\n",
    "# -*- Mode: python -*-\n",
    "# A simple reference recommender\n",
    "#\n",
    "#\n",
    "# This is a medical scenario with historical data. \n",
    "#\n",
    "# General functions\n",
    "#\n",
    "# - set_reward\n",
    "# \n",
    "# There is a set of functions for dealing with historical data:\n",
    "#\n",
    "# - fit_data\n",
    "# - fit_treatment_outcome\n",
    "# - estimate_utiltiy\n",
    "#\n",
    "# There is a set of functions for online decision making\n",
    "#\n",
    "# - predict_proba\n",
    "# - recommend\n",
    "# - observe\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NNDoctor:\n",
    "    def __init__(self, \n",
    "                 n_actions=1, \n",
    "                 n_outcomes=1, \n",
    "                 layer_sizes=[64, 16],\n",
    "                 batch_size=5,\n",
    "                 epochs=5,\n",
    "                 optimizer=\"adam\",\n",
    "                 loss=\"binary_crossentropy\",\n",
    "                 alpha = 0.001):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_outcomes = n_outcomes\n",
    "        self.reward = self._default_reward\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def _default_reward(self, action, outcome):\n",
    "        return -0.1*action + outcome\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {k: v for k, v in self.__dict__.items() if not callable(v)}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.build_network(X, y)\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        return self.model.predict(Xtest)\n",
    "    \n",
    "    def build_network(self, X, y):\n",
    "        model = Sequential()\n",
    "        for layer_size in self.layer_sizes:\n",
    "            model.add(Dense(layer_size, activation='elu',kernel_regularizer=regularizers.l2(self.alpha)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss=self.loss,\n",
    "                      optimizer=self.optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return (self.model.predict(X)**2 - y**2).mean()\n",
    "    \n",
    "class NNRecommender:\n",
    "\n",
    "    #################################\n",
    "    # Initialise\n",
    "    #\n",
    "    # Set the recommender with a default number of actions and outcomes.  This is\n",
    "    # because the number of actions in historical data can be\n",
    "    # different from the ones that you can take with your policy.\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, n_actions, n_outcomes):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_outcomes = n_outcomes\n",
    "        self.reward = self._default_reward\n",
    "\n",
    "    ## By default, the reward is just equal to the outcome, as the actions play no role.\n",
    "    def _default_reward(self, action, outcome):\n",
    "        return -0.1*action + outcome\n",
    "\n",
    "    # Set the reward function r(a, y)\n",
    "    def set_reward(self, reward):\n",
    "        self.reward = reward\n",
    "    \n",
    "    ##################################\n",
    "    # Fit a model from patient data.\n",
    "    #\n",
    "    # This will generally speaking be an\n",
    "    # unsupervised model. Anything from a Gaussian mixture model to a\n",
    "    # neural network is a valid choice.  However, you can give special\n",
    "    # meaning to different parts of the data, and use a supervised\n",
    "    # model instead.\n",
    "    def fit_data(self, data):\n",
    "        print(\"Preprocessing data\")\n",
    "        return None\n",
    "\n",
    "    def train_model(self, X, a, y):\n",
    "        param_grid = {'layer_sizes': [[32, 16], [64, 16]],\n",
    "        'batch_size': [5, 10],\n",
    "        'epochs': [1, 5],\n",
    "        'optimizer': ['Adam', 'sgd'],\n",
    "        'loss': ['mse'],\n",
    "        'alpha': [0.001, 0.0001]}\n",
    "        #self.model = GridSearchCV(NNDoctor(), param_grid, cv=10, n_jobs=4)\n",
    "        self.model = NNDoctor()\n",
    "        self.model.fit(np.concatenate((X, a), axis=1), y)\n",
    "        #print(self.model.best_params_)\n",
    "\n",
    "    ## Fit a model from patient data, actions and their effects\n",
    "    ## Here we assume that the outcome is a direct function of data and actions\n",
    "    ## This model can then be used in estimate_utility(), predict_proba() and recommend()\n",
    "    def fit_treatment_outcome(self, data, actions, outcome):\n",
    "        print(\"Fitting treatment outcomes\")\n",
    "        self.train_model(data, actions, outcome)\n",
    "        return self.model\n",
    "\n",
    "    ## Estimate the utility of a specific policy from historical data (data, actions, outcome),\n",
    "    ## where utility is the expected reward of the policy.\n",
    "    ##\n",
    "    ## If policy is not given, simply use the average reward of the observed actions and outcomes.\n",
    "    ##\n",
    "    ## If a policy is given, then you can either use importance\n",
    "    ## sampling, or use the model you have fitted from historical data\n",
    "    ## to get an estimate of the utility.\n",
    "    ##\n",
    "    ## The policy should be a recommender that implements get_action_probability()\n",
    "    def estimate_utility(self, data, actions, outcome, policy=None):\n",
    "        if policy is None:\n",
    "            return self.reward(actions, outcome).mean()\n",
    "        else:\n",
    "            #predictions_ones = self.model.predict(np.concatenate((data, np.ones(len(data)).reshape(-1,1)), axis = 1))\n",
    "            #predictions_zeros = self.model.predict(np.concatenate((data, np.zeros(len(data)).reshape(-1,1)), axis = 1))\n",
    "            #predictions = np.concatenate((predictions_zeros, predictions_ones), axis=1)\n",
    "            #policy_actions = np.array([policy.get_action_probabilities(x) for x in data])\n",
    "            policy_actions = np.array([policy.recommend(x) for x in data])\n",
    "            predicted_outcomes = self.model.predict(np.concatenate((data, policy_actions.reshape(-1,1)), axis=1))\n",
    "            return self.reward(policy_actions, predicted_outcomes.reshape(1,-1)).mean()\n",
    "            #print(policy_actions)\n",
    "            #res_matrix = np.dot(predictions.T, policy_actions)\n",
    "            #print(res_matrix)\n",
    "            #return (-0.1*policy_actions.sum() + (res_matrix[0][0] + res_matrix[1][1])) / len(data)\n",
    "\n",
    "    # Return a distribution of effects for a given person's data and a specific treatment.\n",
    "    # This should be an numpy.array of length self.n_outcomes\n",
    "    def predict_proba(self, data, treatment):\n",
    "        predictions = self.model.predict(np.concatenate((data, [treatment])).reshape(1,-1)).ravel()\n",
    "        return predictions\n",
    "\n",
    "    # Return a distribution of recommendations for a specific user datum\n",
    "    # This should a numpy array of size equal to self.n_actions, summing up to 1\n",
    "    def get_action_probabilities(self, user_data):\n",
    "        #print(\"Recommending\")\n",
    "        predictions = []\n",
    "        for a in range(self.n_actions):\n",
    "            estimated_outcome = self.model.predict(np.concatenate((user_data, [a])).reshape(1,-1))[0][0]\n",
    "            estimated_reward = self.reward(a, estimated_outcome)\n",
    "            predictions.append(estimated_reward)\n",
    "        return np.exp(predictions)/np.sum(np.exp(predictions))\n",
    "    \n",
    "    def estimate_historic_utility(self, data, actions, outcome):\n",
    "        estimated_outcome = self.model.predict(np.concatenate((data, actions), axis=1))\n",
    "        #outcome_prob = 1/(1 + np.exp(0.5-estimated_outcome))\n",
    "        return self.reward(actions, estimated_outcome).mean()\n",
    "\n",
    "    # Return recommendations for a specific user datum\n",
    "    # This should be an integer in range(self.n_actions)\n",
    "    def recommend(self, user_data):\n",
    "        return np.argmax(self.get_action_probabilities(user_data))\n",
    "\n",
    "    # Observe the effect of an action. This is an opportunity for you\n",
    "    # to refit your models, to take the new information into account.\n",
    "    def observe(self, user, action, outcome):\n",
    "        return None\n",
    "\n",
    "    # After all the data has been obtained, do a final analysis. This can consist of a number of things:\n",
    "    # 1. Recommending a specific fixed treatment policy\n",
    "    # 2. Suggesting looking at specific genes more closely\n",
    "    # 3. Showing whether or not the new treatment might be better than the old, and by how much.\n",
    "    # 4. Outputting an estimate of the advantage of gene-targeting treatments versus the best fixed treatment\n",
    "    def final_analysis(self):\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting treatment outcomes\n",
      "WARNING:tensorflow:From /Users/jolyndevis/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jolyndevis/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jolyndevis/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jolyndevis/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jolyndevis/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jolyndevis/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/jolyndevis/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NNDoctor at 0x1a39231e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NNRecommender(len(np.unique(actions)), outcome.shape[1])\n",
    "f_train, f_test, a_train, a_test, o_train, o_test = train_test_split(features, actions, outcome, test_size=.3)\n",
    "nn.fit_treatment_outcome(f_train, a_train, o_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11912"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1.1:\n",
    "# Implemented estimate_utility above\n",
    "#rec = RandomRecommender(actions.shape[1], actions.shape[1])\n",
    "nn.estimate_utility(features, actions, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean utility: 0.1191\n",
      "Utility std: 0.0033\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD3CAYAAAANMK+RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADdZJREFUeJzt3XGonfV5wPFvklOVbMdwOw6OMYOsGw8MSjGujStxCdERnH9kcwyKVNiyrrSEYXBgUxtJOjpqt8bVUduVuuDoKhO1ssnmTKlDMs0qpI6ttDxWu+L2R8c1uzG3pp1E7/44J+U03nvuvSfvyXvvc78fEM5578k5z+++J9/7+uacc9fNzc0hSVr91rc9gCSpGQZdkoow6JJUhEGXpCIMuiQV0WnzwaenZ0u9xGZqaiMzM2faHuOiW6vrBtfu2tvR63XXzbfdI/QGdTob2h6hFWt13eDa16qVunaDLklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMuSUW0+tZ/aTF77n6qlcc9sn9nK48rXQiP0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVMfIXXETE24AjwFXApcAngP8GHge+M7jZ5zPzoYg4CNwEnAX2ZeZzkxpakvRWi/3GovcDJzPz1oj4GeB54I+BezLz8LkbRcQWYDuwFbgSeBR492RGliavrd+UBP62JI1vsaA/DDwydP0scA0QEbGb/lH6PmAbcDQz54CXI6ITEb3MnB5151NTG+l0Now//QrU63XbHqEVa3Xdk7CavperadamrcS1jwx6Zv4AICK69MN+gP6pl/sz80REfAw4CJwCTg790VlgEzAy6DMzZ8affAXq9bpMT8+2PcZFt1bXPSmr5Xu5lvd722tf6IfJov8oGhFXAv8MfCkzHwQey8wTgy8/BlwNnAaGH6FLP/KSpItkZNAj4grgKPCRzDwy2PxkRLxncPl64ATwDLArItZHxGZgfWa+MqmhJUlvtdg59DuBKeCuiLhrsO124DMR8TrwfeCDmXk6Io4Bx+n/kNg7qYElSfNb7Bz6bcBt83zpvfPc9hBwqJGpJEnL5huLJKkIgy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkorojPpiRLwNOAJcBVwKfAL4FvAAMAd8E9ibmW9GxEHgJuAssC8zn5vc2JKk8y12hP5+4GRmXgfcCHwWuAc4MNi2DtgdEVuA7cBW4H3AfZMbWZI0n8WC/jBw19D1s8A1wNOD608ANwDbgKOZOZeZLwOdiOg1PawkaWEjT7lk5g8AIqILPAIcAD6dmXODm8wCm4DLgZNDf/Tc9ulR9z81tZFOZ8N4k69QvV637RFasVbXPQmr6Xu5mmZt2kpc+8igA0TElcBjwOcy88GI+NOhL3eBU8DpweXzt480M3NmedOucL1el+np2bbHuOjW6ronZbV8L9fyfm977Qv9MBl5yiUirgCOAh/JzCODzc9HxI7B5RuBY8AzwK6IWB8Rm4H1mflKE4NLkpZmsSP0O4Ep4K6IOHcu/TbgLyLiEuDbwCOZ+UZEHAOO0/8hsXdSA0uS5rfYOfTb6Af8fNvnue0h4FAjU0mSls03FklSEQZdkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpiEV/Y5G05+6n2h5B0hJ4hC5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQV4evQpRWmrdf9H9m/s5XHVXM8QpekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKWNLr0CNiK/CpzNwREVuAx4HvDL78+cx8KCIOAjcBZ4F9mfncRCaWJM1r0aBHxB3ArcBrg01bgHsy8/DQbbYA24GtwJXAo8C7G59WkrSgpRyhvwTcDHxpcP0aICJiN/2j9H3ANuBoZs4BL0dEJyJ6mTk96o6npjbS6WwYf/oVqNfrtj2CNJZxnrtr+fm+Ete+aNAz89GIuGpo03PA/Zl5IiI+BhwETgEnh24zC2wCRgZ9ZubMsgdeyXq9LtPTs22PIY1luc/dtfx8b3vtC/0wGecfRR/LzBPnLgNXA6eB4Ufo0o+8JOkiGSfoT0bEewaXrwdOAM8AuyJifURsBtZn5itNDSlJWtw4n7b4YeCzEfE68H3gg5l5OiKOAcfp/5DY2+CMkqQlWFLQM/N7wLWDy98A3jvPbQ4Bh5obTZK0HL6xSJKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJamIzlJuFBFbgU9l5o6I+EXgAWAO+CawNzPfjIiDwE3AWWBfZj43oZklSfNY9Ag9Iu4A7gcuG2y6BziQmdcB64DdEbEF2A5sBd4H3DeZcSVJC1nKKZeXgJuHrl8DPD24/ARwA7ANOJqZc5n5MtCJiF6jk0qSRlr0lEtmPhoRVw1tWpeZc4PLs8Am4HLg5NBtzm2fHnXfU1Mb6XQ2LGvgla7X67Y9gjSWcZ67a/n5vhLXvqRz6Od5c+hyFzgFnB5cPn/7SDMzZ8Z4+JWr1+syPT3b9hjSWJb73F3Lz/e2177QD5NxXuXyfETsGFy+ETgGPAPsioj1EbEZWJ+Zr4wzqCRpPOMcof8R8MWIuAT4NvBIZr4REceA4/R/SOxtcEZJ0hIsKeiZ+T3g2sHlF+i/ouX82xwCDjU3miRpOXxjkSQVYdAlqQiDLklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCIMuiQVYdAlqQiDLklFGHRJKsKgS1IRnbYH0NLtufuptkdQYW0+v47s39naY1cydtAj4nng1cHV/wS+ANwLnAWOZubHL3w8SdJSjRX0iLgMIDN3DG37N+C3ge8C/xARWzLzG00MKUla3LhH6O8CNkbE0cF9HAIuzcyXACLiSeB6YGTQp6Y20ulsGHOElanX67Y9grTqrMa/Nytx5nGDfgb4NHA/8EvAE8Cpoa/PAr+w2J3MzJwZ8+FXpl6vy/T0bNtjSKvOavt70/bf9YV+mIwb9BeAFzNzDnghIl4F3j709S4/GXhJ0oSN+7LFPcBhgIj4OWAj8FpEvCMi1gG7gGPNjChJWopxj9D/CnggIv4FmKMf+DeBLwMb6L/K5evNjChJWoqxgp6ZrwO3zPOlay9sHEnSuHynqCQVYdAlqQiDLklFGHRJKsKgS1IRBl2SijDoklSEQZekIgy6JBVh0CWpCIMuSUUYdEkqwqBLUhEGXZKKMOiSVIRBl6QiDLokFWHQJakIgy5JRRh0SSrCoEtSEQZdkoow6JJURKftASRpz91PtfK4R/bvbOVxJ8WgL1NbTzxJWoynXCSpCIMuSUUYdEkqwqBLUhGN/qNoRKwHPge8C/g/4AOZ+WKTjyFJml/Tr3L5TeCyzPzViLgWOAzsbvgxAF9tIunCVXu5ZNOnXLYB/wSQmf8K/ErD9y9JWkDTR+iXA68OXX8jIjqZeXa+G/d63XXjPtDjhydy4C9Jq1bTR+inge7w/S8Uc0lSs5oO+jPAbwAMzqH/R8P3L0laQNOnXB4Dfj0ingXWAb/X8P1Lkhawbm5uru0ZJEkN8I1FklSEQZekIgy6JBXh56GPsJSPMoiIHvAs8M7M/NHQ9t8Cficzbxlcvxa4FzgLHM3Mj1+cVSxfw+u+Gfgz4L8GNzmYmU9PfhXjGWftEbEJ+Bv678O4BLg9M4+vpn0Oja99Lez3nwIeBN4OvAbcmpnTbe53j9BH+/FHGQD76X+UwY9FxC7gKHDFedvvBT7JT35//xK4hf67abdGxJYJzn2hmlz3FuCOzNwx+G/F/qUeGGfttwNfy8ztwO8C9w22r6Z9Ds2ufS3s9z8ATmTmdcDfAgcG21vb7wZ9tMU+yuBN4Abgf8/b/izw4XNXIuJy4NLMfCkz54AngesnNXQDGln3wDXAnog4FhGHI2Kl/1/hOGv/c+ALg8sd4EercJ9DQ2sfXC6/3zPzM8CfDK5uBv6n7f1u0Eeb96MMzl3JzK9m5snz/1BmPgQMvx70cvrvoj1nFtjU8KxNamrdAF8F/hD4NeCngQ81P26jlr32zDyVmT+MiJ+lf/rho6y+fQ7NrR3WwH4fbH8jIp6iv9Z/pOX9btBHa+qjDM6/ny5w6kIGm7AmP8LhSGZ+d3C08nfA1Rc83WSNtfaIeCfwNeDOwemF1bbPobm1wxrZ7wCZuRO4Dnh0nvu5qPvdoI/WyEcZZOZp4PWIeEdErAN2Accam7J5jax7sNZ/j4ifH2y6HjjRyISTs+y1R8QvAw8Dt2TmE7Aq9zk0tPY1tN8/GhG3Dq6+BrzR9n5f6ee12vaWjzKIiNuBFzPz75d5Xx8CvgxsoP8v319vdtRGNbLuzJyLiA8AX4mIHwLfAr44kYmbM87aPwlcBtwbEQCvZuZuVtc+hwbXvkb2+xHgryPi9+nv43MfddLafvet/5JUhKdcJKkIgy5JRRh0SSrCoEtSEQZdkoow6JJUhEGXpCL+H40ZYU8akCRYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.2:\n",
    "# Use bootstrap on the historical dataset to estimate variance of the utility\n",
    "n = features.shape[0]\n",
    "num_samples = 1000\n",
    "utils = []\n",
    "for i in range(num_samples):\n",
    "    randlist = np.random.randint(n, size=n)\n",
    "    sample_features = features[randlist]\n",
    "    sample_actions = actions[randlist]\n",
    "    sample_outcome = outcome[randlist]\n",
    "    utils.append(nn.estimate_utility(sample_features, sample_actions, sample_outcome))\n",
    "plt.hist(utils)\n",
    "print(\"mean utility: {0:.4f}\".format(np.mean(utils)))\n",
    "print(\"Utility std: {0:.4f}\".format(np.std(utils)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean utility: 0.1335\n",
      "Utility std: 0.0029\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Exercise 2.1:\n",
    "\n",
    "n = f_test.shape[0]\n",
    "num_samples = 100\n",
    "utils = []\n",
    "for i in range(num_samples):\n",
    "    randlist = np.random.randint(n, size=n)\n",
    "    sample_features = f_test[randlist]\n",
    "    sample_actions = a_test[randlist]\n",
    "    sample_outcome = o_test[randlist]\n",
    "    utils.append(nn.estimate_historic_utility(sample_features, sample_actions, sample_outcome))\n",
    "plt.hist(utils)\n",
    "print(\"mean utility: {0:.4f}\".format(np.mean(utils)))\n",
    "print(\"Utility std: {0:.4f}\".format(np.std(utils)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1118"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.estimate_utility(f_test, a_test, o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45870542218089105"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Excercise 2.2:\n",
    "\n",
    "nn.estimate_utility(f_test, a_test, o_test, nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
