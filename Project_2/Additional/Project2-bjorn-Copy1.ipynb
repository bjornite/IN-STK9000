{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "import scipy.cluster.hierarchy as shc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "features = pd.read_csv('./medical/historical_X.dat', header=None, sep=\" \").values\n",
    "actions = pd.read_csv('./medical/historical_A.dat', header=None, sep=\" \").values\n",
    "outcome = pd.read_csv('./medical/historical_Y.dat', header=None, sep=\" \").values\n",
    "observations = features[:, :128]\n",
    "labels = features[:,128] + features[:,129]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by implementing a model\n",
    "\n",
    "\n",
    "# -*- Mode: python -*-\n",
    "# A simple reference recommender\n",
    "#\n",
    "#\n",
    "# This is a medical scenario with historical data. \n",
    "#\n",
    "# General functions\n",
    "#\n",
    "# - set_reward\n",
    "# \n",
    "# There is a set of functions for dealing with historical data:\n",
    "#\n",
    "# - fit_data\n",
    "# - fit_treatment_outcome\n",
    "# - estimate_utiltiy\n",
    "#\n",
    "# There is a set of functions for online decision making\n",
    "#\n",
    "# - predict_proba\n",
    "# - recommend\n",
    "# - observe\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NNDoctor:\n",
    "    def __init__(self, \n",
    "                 n_actions=1, \n",
    "                 n_outcomes=1, \n",
    "                 layer_sizes=[32, 16],\n",
    "                 batch_size=10,\n",
    "                 epochs=1,\n",
    "                 optimizer=\"sgd\",\n",
    "                 loss=\"binary_crossentropy\",\n",
    "                 alpha = 0.001):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_outcomes = n_outcomes\n",
    "        self.reward = self._default_reward\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.alpha = alpha\n",
    "    def _default_reward(self, action, outcome):\n",
    "        return -0.1*action + outcome\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {k: v for k, v in self.__dict__.items() if not callable(v)}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.build_network(X, y)\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        return self.model.predict(Xtest)\n",
    "    \n",
    "    def predict_classes(self, X):\n",
    "        return self.model.predict_classes(X)\n",
    "    \n",
    "    def build_network(self, X, y):\n",
    "        model = Sequential()\n",
    "        for layer_size in self.layer_sizes:\n",
    "            model.add(Dense(layer_size, activation='elu',kernel_regularizer=regularizers.l2(self.alpha)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss=self.loss,\n",
    "                      optimizer=self.optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return (self.model.predict(X)**2 - y**2).mean()\n",
    "    \n",
    "class NNRecommender:\n",
    "\n",
    "    #################################\n",
    "    # Initialise\n",
    "    #\n",
    "    # Set the recommender with a default number of actions and outcomes.  This is\n",
    "    # because the number of actions in historical data can be\n",
    "    # different from the ones that you can take with your policy.\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, n_actions, n_outcomes):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_outcomes = n_outcomes\n",
    "        self.reward = self._default_reward\n",
    "\n",
    "    ## By default, the reward is just equal to the outcome, as the actions play no role.\n",
    "    def _default_reward(self, action, outcome):\n",
    "        return -0.1*action + outcome\n",
    "\n",
    "    # Set the reward function r(a, y)\n",
    "    def set_reward(self, reward):\n",
    "        self.reward = reward\n",
    "    \n",
    "    ##################################\n",
    "    # Fit a model from patient data.\n",
    "    #\n",
    "    # This will generally speaking be an\n",
    "    # unsupervised model. Anything from a Gaussian mixture model to a\n",
    "    # neural network is a valid choice.  However, you can give special\n",
    "    # meaning to different parts of the data, and use a supervised\n",
    "    # model instead.\n",
    "\n",
    "\n",
    "    ## Fit a model from patient data, actions and their effects\n",
    "    ## Here we assume that the outcome is a direct function of data and actions\n",
    "    ## This model can then be used in estimate_utility(), predict_proba() and recommend()\n",
    "    def fit_treatment_outcome(self, data, actions, outcome):\n",
    "        print(\"Fitting treatment outcomes\")\n",
    "        param_grid = {'layer_sizes': [[32, 16], [64, 16]],\n",
    "        'batch_size': [5, 10],\n",
    "        'epochs': [1, 5],\n",
    "        'optimizer': ['Adam', 'sgd'],\n",
    "        'loss': ['mse'],\n",
    "        'alpha': [0.001, 0.0001]}\n",
    "        #self.model = GridSearchCV(NNDoctor(), param_grid, cv=10, n_jobs=4)\n",
    "        self.model = NNDoctor()\n",
    "        self.model.fit(data, outcome)\n",
    "        #print(self.model.best_params_)\n",
    "        return self.model\n",
    "\n",
    "    ## Estimate the utility of a specific policy from historical data (data, actions, outcome),\n",
    "    ## where utility is the expected reward of the policy.\n",
    "    ##\n",
    "    ## If policy is not given, simply use the average reward of the observed actions and outcomes.\n",
    "    ##\n",
    "    ## If a policy is given, then you can either use importance\n",
    "    ## sampling, or use the model you have fitted from historical data\n",
    "    ## to get an estimate of the utility.\n",
    "    ##\n",
    "    ## The policy should be a recommender that implements get_action_probability()\n",
    "    def estimate_utility(self, data, actions, outcome, policy=None):\n",
    "        if policy is None:\n",
    "            return self.reward(actions, outcome).mean()\n",
    "        else:\n",
    "            policy_actions = np.array([policy.recommend(x) for x in data])\n",
    "            predicted_outcomes = self.model.predict(outcome)\n",
    "            return self.reward(policy_actions, predicted_outcomes.reshape(1,-1)).mean()\n",
    "\n",
    "    # Return a distribution of effects for a given person's data and a specific treatment.\n",
    "    # This should be an numpy.array of length self.n_outcomes\n",
    "    def predict_proba(self, data, treatment):\n",
    "        predictions = self.model.predict(data)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_classes(self, data, treatment):\n",
    "        predictions = self.model.predict_classes(data)\n",
    "        return predictions\n",
    "\n",
    "    # Return a distribution of recommendations for a specific user datum\n",
    "    # This should a numpy array of size equal to self.n_actions, summing up to 1\n",
    "    def get_action_probabilities(self, user_data):\n",
    "        #print(\"Recommending\")\n",
    "        predictions = []\n",
    "        for a in range(self.n_actions):\n",
    "            estimated_outcome = self.model.predict(np.concatenate((user_data, [a])).reshape(1,-1))[0][0]\n",
    "            #estimated_outcome = self.model.predict(user_data, [])\n",
    "            estimated_reward = self.reward(a, estimated_outcome)\n",
    "            predictions.append(estimated_reward)\n",
    "        return np.exp(predictions)/np.sum(np.exp(predictions))\n",
    "    \n",
    "    def estimate_historic_utility(self, data, actions, outcome):\n",
    "        estimated_outcome = self.model.predict(np.concatenate((data, actions), axis=1))\n",
    "        #outcome_prob = 1/(1 + np.exp(0.5-estimated_outcome))\n",
    "        return self.reward(actions, estimated_outcome).mean()\n",
    "\n",
    "    # Return recommendations for a specific user datum\n",
    "    # This should be an integer in range(self.n_actions)\n",
    "    def recommend(self, user_data):\n",
    "        return np.argmax(self.get_action_probabilities(user_data))\n",
    "\n",
    "    # Observe the effect of an action. This is an opportunity for you\n",
    "    # to refit your models, to take the new information into account.\n",
    "    def observe(self, user, action, outcome):\n",
    "        return None\n",
    "\n",
    "    # After all the data has been obtained, do a final analysis. This can consist of a number of things:\n",
    "    # 1. Recommending a specific fixed treatment policy\n",
    "    # 2. Suggesting looking at specific genes more closely\n",
    "    # 3. Showing whether or not the new treatment might be better than the old, and by how much.\n",
    "    # 4. Outputting an estimate of the advantage of gene-targeting treatments versus the best fixed treatment\n",
    "    def final_analysis(self):\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "Fitting treatment outcomes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NNDoctor at 0x1a333ad320>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NNRecommender(len(np.unique(actions)), outcome.shape[1])\n",
    "\n",
    "print(len(np.unique(actions)))\n",
    "print(outcome.shape[1])\n",
    "\n",
    "f_train, f_test, a_train, a_test, o_train, o_test = train_test_split(features, actions, outcome, test_size=.3)\n",
    "\n",
    "nn.fit_treatment_outcome(f_train, a_train, o_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 130)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38350713],\n",
       "       [0.12638924],\n",
       "       [0.03470078],\n",
       "       ...,\n",
       "       [0.04300708],\n",
       "       [0.2909507 ],\n",
       "       [0.10310835]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict_proba(features, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 9840, 1: 160}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = nn.predict_classes(features, actions)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "unique, counts = np.unique(pred, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.get_action_probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11912"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1.1:\n",
    "# Implemented estimate_utility above\n",
    "#rec = RandomRecommender(actions.shape[1], actions.shape[1])\n",
    "nn.estimate_utility(features, actions, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean utility: 0.1192\n",
      "Utility std: 0.0032\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.2:\n",
    "# Use bootstrap on the historical dataset to estimate variance of the utility\n",
    "n = features.shape[0]\n",
    "num_samples = 1000\n",
    "utils = []\n",
    "for i in range(num_samples):\n",
    "    randlist = np.random.randint(n, size=n)\n",
    "    sample_features = features[randlist]\n",
    "    sample_actions = actions[randlist]\n",
    "    sample_outcome = outcome[randlist]\n",
    "    utils.append(nn.estimate_utility(sample_features, sample_actions, sample_outcome))\n",
    "plt.hist(utils)\n",
    "print(\"mean utility: {0:.4f}\".format(np.mean(utils)))\n",
    "print(\"Utility std: {0:.4f}\".format(np.std(utils)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected sequential_5_input to have shape (130,) but got array with shape (131,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1f35714417f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msample_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msample_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_historic_utility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_outcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean utility: {0:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d64def651274>\u001b[0m in \u001b[0;36mestimate_historic_utility\u001b[0;34m(self, data, actions, outcome)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mestimate_historic_utility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mestimated_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;31m#outcome_prob = 1/(1 + np.exp(0.5-estimated_outcome))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_outcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d64def651274>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Xtest)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected sequential_5_input to have shape (130,) but got array with shape (131,)"
     ]
    }
   ],
   "source": [
    "#Exercise 2.1:\n",
    "\n",
    "n = f_test.shape[0]\n",
    "num_samples = 100\n",
    "utils = []\n",
    "for i in range(num_samples):\n",
    "    randlist = np.random.randint(n, size=n)\n",
    "    sample_features = f_test[randlist]\n",
    "    sample_actions = a_test[randlist]\n",
    "    sample_outcome = o_test[randlist]\n",
    "    utils.append(nn.estimate_historic_utility(sample_features, sample_actions, sample_outcome))\n",
    "plt.hist(utils)\n",
    "print(\"mean utility: {0:.4f}\".format(np.mean(utils)))\n",
    "print(\"Utility std: {0:.4f}\".format(np.std(utils)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12876666666666664"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.estimate_utility(f_test, a_test, o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34131958809594054"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Excercise 2.2:\n",
    "\n",
    "nn.estimate_utility(f_test, a_test, o_test, nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
